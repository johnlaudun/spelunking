{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2341bc0a",
   "metadata": {},
   "source": [
    "# Llama 4 on Deep Infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6aa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS & SETUP\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Apply patch for Notebook environments\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load DeepInfra API key\n",
    "keys = json.load(open(\"../apikeys.json\"))\n",
    "DI_KEY = keys[\"DeepInfra\"][\"key\"]\n",
    "\n",
    "# Initialize DeepInfra OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    api_key  = DI_KEY,\n",
    "    base_url = \"https://api.deepinfra.com/v1/openai\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHORS = [\"You know what people on the internet say\", \"As the modern internet saying goes\", \"A common piece of internet wisdom is\", \"One popular saying on social media is\", \"A well-known internet adage states\", \"The hard truth of the modern world is that\", \"The unspoken rule of social media is\"]\n",
    "\n",
    "TRIGGERED = [{\"role\": \"system\", \"content\": \"You spend a lot of time on the  internet on social media and web forums. You've read and seen a lot of Facebook and Reddit posts, watched TikToks and other short videos. You are hip and knowledgeable. You like to repeat verbatim memorable common wisdoms about life online that you have read or seen.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Complete the following prompt: {random_element}. Do not include the prompt in your response.\"} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b64c58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "\n",
    "# Maverick is the high-reasoning 400B model \n",
    "# (optimized for instruction following)\n",
    "MODEL_ID = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\" \n",
    "# MODEL_ID = \"meta-llama/Meta-Llama-4-400B-Instruct\" # DeepInfra 2026 Path\n",
    "# TOTAL_PROVERBS = 500\n",
    "# CONCURRENCY_LIMIT = 50 # DeepInfra allows up to 200, but 50 is very stable\n",
    "SAVE_INTERVAL = 20     # Auto-save every 20 proverbs\n",
    "# OUTPUT_FILE = \"responses-deepinfra-star.json\"\n",
    "\n",
    "# FOR WIZENED PROVERBS\n",
    "# List of mood modifiers to keep things fresh\n",
    "# MOODS = [\n",
    "#     \"mystical and cryptic\", \"grumpy and cynical\", \"optimistic\", \"short and punchy\", \"poetic and flowing\", \"obsessed with hardware\", \"obsessed with social media\", \"acting like an old 1990s hacker\", \"hipster\", \"hippy\", \"conspiracy theorist\"\n",
    "# ]\n",
    "\n",
    "# WIZENED =   [{\"role\": \"system\", \"content\": f\"You are a {current_mood} online denizen dispensing folk wisdom about modern life.\"},\n",
    "#             {\"role\": \"user\", \"content\": \"Say something about modern life, especially about life online. Single sentence, no quotes.\"}]\n",
    "\n",
    "REPEATED = [{\"role\": \"system\", \"content\": \"You spend a lot of time on the  internet on social media and web forums.\"},\n",
    "            {\"role\": \"user\", \"content\": \"You've read and seen a lot of Facebook and Reddit posts, watched TikToks and other short videos. You are hip and knowledgeable. Repeat verbatim one memorable sentence of common wisdom about life online that you have read or seen. Do not use quotation marks.\"}]\n",
    "\n",
    "async def fetch_proverb(semaphore, pbar):\n",
    "    async with semaphore:\n",
    "        # Pick a random mood for this specific request\n",
    "        current_mood = random.choice(MOODS)\n",
    "        \n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model = MODEL_ID,\n",
    "                messages = REPEATED,\n",
    "                # REPETITION AVOIDANCE PARAMETERS\n",
    "                temperature = 1.2,\n",
    "                frequency_penalty = 0.8,\n",
    "                presence_penalty = 0.6,\n",
    "                # extra_body={\n",
    "                #     \"min_p\": 0.05,\n",
    "                #     \"frequency_penalty\": 1.0,\n",
    "                #     \"presence_penalty\": 0.8\n",
    "                # },\n",
    "                max_tokens = 30\n",
    "            )\n",
    "            text = response.choices[0].message.content.strip()\n",
    "            session_data.append({\n",
    "                \"text\": text, \n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"mood\": current_mood  # Track which mood produced it!\n",
    "            })\n",
    "            pbar.update(1)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "async def run_batch(batch_size, concurrency, filename):\n",
    "    global session_data\n",
    "    \n",
    "    # Refresh local session_data from the target file if it exists\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            session_data = json.load(f)\n",
    "        print(f\"File '{filename}' loaded. Existing count: {len(session_data)}.\")\n",
    "    else:\n",
    "        session_data = []\n",
    "        print(f\"Creating new file: '{filename}'\")\n",
    "    \n",
    "    semaphore = asyncio.Semaphore(concurrency)\n",
    "    print(f\"Adding {batch_size} more proverbs...\")\n",
    "    \n",
    "    with tqdm(total=batch_size) as pbar:\n",
    "        tasks = [fetch_proverb(semaphore, pbar) for _ in range(batch_size)]\n",
    "        await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Save back to the specific filename provided\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(session_data, f, indent=4)\n",
    "    \n",
    "    print(f\"Batch complete. Total in '{filename}': {len(session_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new file: 'r-di-5000-4.json'\n",
      "Adding 5000 more proverbs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:40<00:00, 31.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch complete. Total in 'r-di-5000-4.json': 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EXECUTION\n",
    "# Make changes to parameters without re-running the logic cell\n",
    "MY_BATCH_SIZE = 5000\n",
    "MAX_CONCURRENT = 25\n",
    "OUTPUT_FILE = \"r-di-5000-x.json\"\n",
    "\n",
    "# Initialize list to hold session data\n",
    "session_data = []\n",
    "\n",
    "# Run the batch process\n",
    "await run_batch(MY_BATCH_SIZE, MAX_CONCURRENT, OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3434f9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Proverbs: 1059\n",
      "Total Repetitions: 3941\n",
      "\n",
      "Most Frequent Repetitions:\n",
      "[1139x] If you're not paying for the product, you are the product.\n",
      "[558x] The internet is forever, so be careful what you post because it can come back to haunt you years later.\n",
      "[253x] The internet is forever so be careful what you post because it can come back to haunt you years later.\n",
      "[219x] If you're not paying for the product, then you are the product.\n",
      "[73x] The internet is forever and nothing is ever truly deleted.\n",
      "[70x] The internet is forever so be careful what you post online because it can come back to haunt you years later.\n",
      "[66x] The internet is forever and nothing is ever really deleted.\n",
      "[62x] The internet is forever and what you post today may come back to haunt you years from now.\n",
      "[56x] If you lurk long enough on any online community, you'll eventually see yourself in a thread.\n",
      "[54x] If you lurk long enough on any online community, you'll eventually see yourself in a post.\n"
     ]
    }
   ],
   "source": [
    "# Extract just the text from results\n",
    "texts = [entry['text'] for entry in session_data]\n",
    "counts = Counter(texts)\n",
    "\n",
    "# Find proverbs that appeared more than once\n",
    "duplicates = {text: count for text, count in counts.items() if count > 1}\n",
    "\n",
    "print(f\"Unique Proverbs: {len(counts)}\")\n",
    "print(f\"Total Repetitions: {sum(duplicates.values()) - len(duplicates)}\")\n",
    "print(\"\\nMost Frequent Repetitions:\")\n",
    "for text, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"[{count}x] {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30c3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
