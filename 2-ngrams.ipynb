{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2341bc0a",
   "metadata": {},
   "source": [
    "# Ngrams\n",
    "\n",
    "An n-gram is a contiguous sequence of 'n' items from a given sample of text or speech. Widely used in natural language processing for tasks like text prediction, language modeling, and machine translation, here we are looking for the folkloristic version of an ngram, the proverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4384136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "\"Silence can be a powerful statement amidst the noise of social media.\",\n",
      "\n",
      "\"Reposts reveal not just your interests but your values.\",\n",
      "\n",
      "\"Block out the noise that threatens your peace of mind.\",\n",
      "\n",
      "\"Filters can distort reality, but authenticity shines through.\",\n",
      "\n",
      "\"Be the signal in a sea of noise.\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# Read file into one big text:\n",
    "with open('responses-2-100.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "texts = lines[1:-1]  # Exclude first and last line\n",
    "\n",
    "print(len(texts))\n",
    "for text in texts[-5:]:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdabd025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens after preprocessing: 4986\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenizes text and converts to lowercase, removing punctuation.\"\"\"\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word not in string.punctuation and word.isalnum()]\n",
    "    return tokens\n",
    "\n",
    "# Get the tokenized list from the corpus\n",
    "word_tokens = preprocess_text(one_big_string)\n",
    "print(f\"Total number of tokens after preprocessing: {len(word_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25915bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ngrams_in_range(tokens, min_n, max_n):\n",
    "    \"\"\"\n",
    "    Generates a list of all n-grams for n within the specified range.\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    # Loop from min_n up to and including max_n\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        # The ngrams function yields tuples of n tokens\n",
    "        n_gram_generator = ngrams(tokens, n)\n",
    "        # Convert the generator results to a list and extend the master list\n",
    "        all_ngrams.extend(list(n_gram_generator))\n",
    "    return all_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "413687c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of a generated 8-gram (first one):\n",
      "do compare your to someone else highlight reel\n"
     ]
    }
   ],
   "source": [
    "# Arbitrary numbers until they are not:\n",
    "MIN_N = 8\n",
    "MAX_N = 20\n",
    "\n",
    "# Get all n-grams\n",
    "long_ngrams = get_all_ngrams_in_range(word_tokens, MIN_N, MAX_N)\n",
    "\n",
    "# The n-grams are returned as tuples of tokens, e.g., ('the', 'complexity', 'of', 'modern', 'life', 'often', 'masks', 'the')\n",
    "# We can join them to view them as phrases:\n",
    "print(f\"\\nExample of a generated {MIN_N}-gram (first one):\")\n",
    "print(' '.join(long_ngrams[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1bbae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 10 Most Frequent N-grams (8 to 20 tokens) ---\n",
      "[8-gram, Count: 15]: \"always believe that something wonderful is about to\"\n",
      "[8-gram, Count: 15]: \"believe that something wonderful is about to happen\"\n",
      "[9-gram, Count: 15]: \"always believe that something wonderful is about to happen\"\n",
      "[8-gram, Count: 14]: \"keep your face always toward the sunshine and\"\n",
      "[8-gram, Count: 14]: \"your face always toward the sunshine and shadows\"\n",
      "[8-gram, Count: 14]: \"face always toward the sunshine and shadows will\"\n",
      "[8-gram, Count: 14]: \"always toward the sunshine and shadows will fall\"\n",
      "[8-gram, Count: 14]: \"toward the sunshine and shadows will fall behind\"\n",
      "[8-gram, Count: 14]: \"the sunshine and shadows will fall behind you\"\n",
      "[8-gram, Count: 14]: \"happiness is not the absence of problems it\"\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each unique n-gram\n",
    "ngram_counts = Counter(long_ngrams)\n",
    "\n",
    "# Define how many top results you want to see\n",
    "TOP_K = 10 \n",
    "\n",
    "# Get the top K most common n-grams\n",
    "most_common_ngrams = ngram_counts.most_common(TOP_K)\n",
    "\n",
    "print(f\"\\n--- Top {TOP_K} Most Frequent N-grams ({MIN_N} to {MAX_N} tokens) ---\")\n",
    "for n_gram_tuple, count in most_common_ngrams:\n",
    "    # Join the tuple tokens into a single string phrase\n",
    "    phrase = ' '.join(n_gram_tuple)\n",
    "    n_length = len(n_gram_tuple)\n",
    "    print(f\"[{n_length}-gram, Count: {count}]: \\\"{phrase}\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
